We were given two sets of 1'250'000 tweets, one containing negative evaluated tweets (contained a negative smiley) and the other positive tweets (contained a positive smiley), making a total of 2'500'000 tweets for training. As this is a huge amount of data and thus computationally expensive, we first explored and tried different methods with a smaller set of 200'000 tweets, half of them evaluated positive and half of them negative.