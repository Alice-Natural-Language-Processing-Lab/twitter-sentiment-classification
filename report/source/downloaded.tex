We ran the cv on truncated set and saw that the predictions were better on full dataset. As one can easily find more pre-labeled tweets, we were able to enlarge our training set. (This is as more training data will very likely increase the classification accuracy)--> \textbf{true only when our dataset suffers from high variance... which may be the case so we need to put a plot or we can say it learns more words??}\\

The Twitter Sentiment Analysis Dataset obtained from \textit{http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/} contains 1,578,627 classified tweets based on data from the following two sources:\\
University of Michigan Sentiment Analysis competition on Kaggle\\
Twitter Sentiment Corpus by Niek Sanders\\	

Each row is marked as \texttt{1} for positive sentiment and \texttt{0} for negative sentiment that we changed to \texttt{-1} to maintain consistency with our labels \texttt{$\{$1,-1$\}$}.